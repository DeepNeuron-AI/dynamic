{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this notebook for?\n",
    "This notebook is intended only for visualinsing the left and or right ventricle segmentations for a particular echonet video.\n",
    "\n",
    "If you want to add other interesting things to the visualisation (such as estimated septum width, etc.), you should use the [other notebook](./weak_labels.ipynb) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "import scipy\n",
    "\n",
    "import echonet\n",
    "from weak_labels.utils import get_average_eccentricity, get_min_area_rect, get_min_area_box, mask_to_image, image_to_mask, find_corner, get_angle, BOTTOM_LEFT, BOTTOM_RIGHT, remove_septum\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Can assign these colours to numpy arrays so long as the colours are stored in\n",
    "# the last axis of the target array (e.g. image.shape =(112, 112, 3), but not\n",
    "# image.shape = (3, 112, 112)). \n",
    "# Just do image[y_vals, x_vals] = MAGENTA\n",
    "# IMPORTANT: if using within an *opencv* function, you'll want to do \n",
    "# COLOUR.tolist() to convert these to python primitives, else opencv complains about\n",
    "# datatypes\n",
    "# Note also that these are BGR, not RGB, since that's what opencv prefers BGR for historical reasons!\n",
    "RED = np.array([0, 0, 255])\n",
    "GREEN = np.array([0, 255, 0])\n",
    "BLUE = np.array([255, 0, 0])\n",
    "ORANGE = np.array([0, 165, 255])\n",
    "LIGHT_GREY = np.array([211, 211, 211])\n",
    "MAGENTA = np.array([255, 0, 255])\n",
    "YELLOW = np.array([0, 255, 255])\n",
    "WHITE = np.array([255, 255, 255])\n",
    "BLACK = np.array([0, 0, 0])\n",
    "\n",
    "# Just some types for us to use in type hints to make dev easier\n",
    "Point = List[np.intp]\n",
    "Box = Tuple[Point, Point, Point, Point]\n",
    "Rectangle = Tuple[Point, Tuple[float, float], float] # [centre, (width, height), angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heights(masks: np.ndarray) -> np.ndarray:\n",
    "    images = mask_to_image(masks)\n",
    "    heights = np.zeros(len(images))\n",
    "    for i, image in enumerate(images):\n",
    "        ((centre_x, centre_y), (width, height), angle) = get_min_area_rect(image)\n",
    "        height = max(width, height)\n",
    "        heights[i] = height\n",
    "\n",
    "    return heights\n",
    "\n",
    "def get_angles(masks: np.ndarray) -> np.ndarray:\n",
    "    images = mask_to_image(masks)\n",
    "    rects = [get_min_area_rect(image) for image in images]\n",
    "    angles = np.array([get_angle(rect) for rect in rects])\n",
    "    return angles\n",
    "\n",
    "\n",
    "def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:\n",
    "    rect = get_min_area_rect(image)\n",
    "    bottom_left = find_corner(rect, which=BOTTOM_LEFT)\n",
    "    bottom_left = (int(bottom_left[0]), int(bottom_left[1]))\n",
    "\n",
    "    rot_mat = cv2.getRotationMatrix2D(bottom_left, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def get_diastoles_systoles(LV_masks):\n",
    "    LV_areas = LV_masks.sum(axis=(1,2))\n",
    "    min_area, max_area = LV_areas.min(), LV_areas.max()\n",
    "    trim_min = sorted(LV_areas)[round(len(LV_areas) ** 0.05)]\n",
    "    trim_max = sorted(LV_areas)[round(len(LV_areas) ** 0.95)]\n",
    "    trim_range = trim_max - trim_min\n",
    "    diastoles = scipy.signal.find_peaks(LV_areas, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "    systoles = scipy.signal.find_peaks(-LV_areas, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "\n",
    "    return diastoles, systoles\n",
    "\n",
    "def crop_box(image: np.ndarray, box: np.array) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    (num_points, x, y)\n",
    "    [\n",
    "        [ 64 464]\n",
    "        [ 64  64]\n",
    "        [464  64]\n",
    "        [464 464]\n",
    "    ]\n",
    "    \"\"\"\n",
    "    min_x = min(p[0] for p in box)\n",
    "    max_x = max(p[0] for p in box)\n",
    "    min_y = min(p[1] for p in box)\n",
    "    max_y = max(p[1] for p in box)\n",
    "    return image[min_y:max_y, min_x:max_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "echonet_video_fp = (Path\n",
    "(config[\"ECHONET_VIDEO_DIR\"]) / config[\"VIDEONAME\"]).with_suffix(\".avi\")\n",
    "echonet_video = echonet.utils.loadvideo(str(echonet_video_fp))\n",
    "echonet_video = echonet_video.transpose((1, 2, 3, 0)) # Put colour axis at end for easier colouring of pixels\n",
    "\n",
    "LV_masks = np.load(config[\"LV_MASKS\"])\n",
    "RV_masks = np.load(config[\"RV_MASKS\"])\n",
    "\n",
    "num_frames, frame_height, frame_width = LV_masks.shape\n",
    "out_height = (frame_height + frame_height // 8) * 4\n",
    "out_width = frame_width * 4\n",
    "out_size = (out_width, out_height)\n",
    "if WRITE:\n",
    "    print(f\"Size: ({frame_width}, {frame_height}) -> ({out_size})\")\n",
    "\n",
    "WINDOW = f\"Segmentation: {config['VIDEONAME']}.avi\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "\n",
    "i = 0\n",
    "is_playing = True\n",
    "\n",
    "if WRITE:\n",
    "    writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), 30, out_size)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if i >= num_frames:\n",
    "            i = 0\n",
    "            if WRITE:\n",
    "                break\n",
    "        elif i < 0:\n",
    "            i = num_frames - 1\n",
    "\n",
    "        # Copy data for this particular frame\n",
    "        frame = echonet_video[i].copy()\n",
    "        LV_mask = LV_masks[i].copy()\n",
    "        RV_mask = RV_masks[i].copy()\n",
    "\n",
    "        ######## SEGMENTATIONS\n",
    "        frame[LV_mask] = RED\n",
    "        frame[RV_mask] = BLUE\n",
    "\n",
    "        LV_box = get_min_area_box(mask_to_image(LV_mask))\n",
    "        RV_box = get_min_area_box(mask_to_image(RV_mask))\n",
    "        cv2.drawContours(frame, [LV_box], 0, YELLOW.tolist())\n",
    "        cv2.drawContours(frame, [RV_box], 0, ORANGE.tolist())\n",
    "\n",
    "        ####### ADD FRAME COUNTER AT TOP\n",
    "        top_border = np.zeros((frame_height // 8, frame_width, 3), dtype=frame.dtype)\n",
    "        top_border[:, :] = np.expand_dims(LIGHT_GREY, (0, 1))\n",
    "        cv2.putText(top_border, f\"Frame {i+1}/{num_frames}\", org=(5,10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.25, color=RED.tolist())\n",
    "        frame = np.concatenate([top_border, frame], axis=0)\n",
    "\n",
    "        ######## SHOW SEGMENTATION AND HANDLE KEYPRESS\n",
    "        cv2.imshow(WINDOW, frame)\n",
    "\n",
    "        if WRITE:\n",
    "            frame = cv2.resize(frame, out_size)\n",
    "            writer.write(frame)\n",
    "\n",
    "        keypress = cv2.waitKey(25) & 0xFF\n",
    "        if keypress == ord('q'):\n",
    "            break\n",
    "        elif keypress == ord(' '):\n",
    "            is_playing = not is_playing\n",
    "        elif keypress == ord('a'):\n",
    "            i -= 1\n",
    "        elif keypress == ord('d'):\n",
    "            i += 1\n",
    "        else:\n",
    "            if is_playing:\n",
    "                i += 1\n",
    "finally:\n",
    "    cv2.destroyAllWindows() \n",
    "    if WRITE:\n",
    "        writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
