{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this notebook for?\n",
    "This notebook is intended only for visualinsing the left and or right ventricle segmentations for a particular echonet video.\n",
    "\n",
    "If you want to add other interesting things to the visualisation (such as estimated septum width, etc.), you should use the [other notebook](./weak_labels.ipynb) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "import scipy\n",
    "\n",
    "import echonet\n",
    "from weak_labels.utils import get_average_eccentricity, get_min_area_rect, get_min_area_box, mask_to_image, image_to_mask, find_corner, get_angle, BOTTOM_LEFT, BOTTOM_RIGHT, remove_septum\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Can assign these colours to numpy arrays so long as the colours are stored in\n",
    "# the last axis of the target array (e.g. image.shape =(112, 112, 3), but not\n",
    "# image.shape = (3, 112, 112)). \n",
    "# Just do image[y_vals, x_vals] = MAGENTA\n",
    "# IMPORTANT: if using within an *opencv* function, you'll want to do \n",
    "# COLOUR.tolist() to convert these to python primitives, else opencv complains about\n",
    "# datatypes\n",
    "# Note also that these are BGR, not RGB, since that's what opencv prefers BGR for historical reasons!\n",
    "RED = np.array([0, 0, 255])\n",
    "GREEN = np.array([0, 255, 0])\n",
    "BLUE = np.array([255, 0, 0])\n",
    "ORANGE = np.array([0, 165, 255])\n",
    "LIGHT_GREY = np.array([211, 211, 211])\n",
    "MAGENTA = np.array([255, 0, 255])\n",
    "YELLOW = np.array([0, 255, 255])\n",
    "WHITE = np.array([255, 255, 255])\n",
    "BLACK = np.array([0, 0, 0])\n",
    "\n",
    "# Just some types for us to use in type hints to make dev easier\n",
    "Point = List[np.intp]\n",
    "Box = Tuple[Point, Point, Point, Point]\n",
    "Rectangle = Tuple[Point, Tuple[float, float], float] # [centre, (width, height), angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heights(masks: np.ndarray) -> np.ndarray:\n",
    "    images = mask_to_image(masks)\n",
    "    heights = np.zeros(len(images))\n",
    "    for i, image in enumerate(images):\n",
    "        ((centre_x, centre_y), (width, height), angle) = get_min_area_rect(image)\n",
    "        height = max(width, height)\n",
    "        heights[i] = height\n",
    "\n",
    "    return heights\n",
    "\n",
    "def get_angles(masks: np.ndarray) -> np.ndarray:\n",
    "    images = mask_to_image(masks)\n",
    "    rects = [get_min_area_rect(image) for image in images]\n",
    "    angles = np.array([get_angle(rect) for rect in rects])\n",
    "    return angles\n",
    "\n",
    "\n",
    "def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:\n",
    "    rect = get_min_area_rect(image)\n",
    "    bottom_left = find_corner(rect, which=BOTTOM_LEFT)\n",
    "    bottom_left = (int(bottom_left[0]), int(bottom_left[1]))\n",
    "\n",
    "    rot_mat = cv2.getRotationMatrix2D(bottom_left, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def get_diastoles_systoles(LV_masks):\n",
    "    LV_areas = LV_masks.sum(axis=(1,2))\n",
    "    min_area, max_area = LV_areas.min(), LV_areas.max()\n",
    "    trim_min = sorted(LV_areas)[round(len(LV_areas) ** 0.05)]\n",
    "    trim_max = sorted(LV_areas)[round(len(LV_areas) ** 0.95)]\n",
    "    trim_range = trim_max - trim_min\n",
    "    diastoles = scipy.signal.find_peaks(LV_areas, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "    systoles = scipy.signal.find_peaks(-LV_areas, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "\n",
    "    return diastoles, systoles\n",
    "\n",
    "def crop_box(image: np.ndarray, box: np.array) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    (num_points, x, y)\n",
    "    [\n",
    "        [ 64 464]\n",
    "        [ 64  64]\n",
    "        [464  64]\n",
    "        [464 464]\n",
    "    ]\n",
    "    \"\"\"\n",
    "    min_x = min(p[0] for p in box)\n",
    "    max_x = max(p[0] for p in box)\n",
    "    min_y = min(p[1] for p in box)\n",
    "    max_y = max(p[1] for p in box)\n",
    "    return image[min_y:max_y, min_x:max_x]\n",
    "\n",
    "\n",
    "def get_centroid(mask: np.ndarray) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Taken from: https://learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/\n",
    "    \"\"\"\n",
    "    image = mask_to_image(mask)\n",
    "    M = cv2.moments(image)\n",
    "        \n",
    "    # calculate x,y coordinate of center\n",
    "    centre_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "    centre_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return (centre_x, centre_y)\n",
    "\n",
    "\n",
    "def get_radial_distances(mask: np.ndarray) -> np.ndarray:\n",
    "    image = mask_to_image(mask)\n",
    "\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = contours[0]\n",
    "    contour = np.squeeze(contour)\n",
    "    # # Apex actually seems to be at index 0 every time, but do this to be safe\n",
    "    # apex = contour[np.argmin(contour[:, 1])]\n",
    "    centre = np.array(get_centroid(mask))\n",
    "    radial_dists = np.linalg.norm(contour - centre, axis=1)\n",
    "    return radial_dists\n",
    "\n",
    "def get_radial_distance_correlation(LV_masks: np.ndarray, RV_masks: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Returns the average \"radial\" distance correlation between the LV and the RV \n",
    "    for the given video masks, as a tuple of (mean, standard deviation).\n",
    "\n",
    "    Note that the \"radial\" distance is calculated using the centre-of-mass of\n",
    "    the ventricle's segmentation, then calculating the distance from this centre\n",
    "    to every point along the ventricle's outer contour.\n",
    "\n",
    "    If the LV and RV were true mirror images of each other, this correlation would\n",
    "    be ~1, but since they are definitely not identical in shape, the true threshold\n",
    "    for a \"good\" correlation will likely be much lower.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (mean, std): Tuple[float, float]\n",
    "        Mean and standard deviation of correlation between LV and RV \"radial\"\n",
    "        distances.\n",
    "    \"\"\"\n",
    "    LV_radial_dists = [get_radial_distances(mask) for mask in LV_masks]\n",
    "    RV_radial_dists = [get_radial_distances(mask) for mask in RV_masks]\n",
    "    correlations = np.zeros(len(LV_masks))\n",
    "\n",
    "    # Get correlation on frame-by-frame basis\n",
    "    for i, (LV_dists, RV_dists) in enumerate(zip(LV_radial_dists, RV_radial_dists)):\n",
    "        # We'll need to pad out the shorter dist array (likely the RV) since one\n",
    "        # ventricle's contour will generally have a different number of points on\n",
    "        # its contour\n",
    "        if len(RV_dists) > len(LV_dists):\n",
    "            shorter_dists = LV_dists\n",
    "            longer_dists = RV_dists\n",
    "        else:\n",
    "            shorter_dists = RV_dists\n",
    "            longer_dists = LV_dists\n",
    "\n",
    "        # Need these index arrays since we interpolate the RV dists\n",
    "        x_interp = np.arange(0, len(longer_dists))\n",
    "        x_current = np.arange(0, len(shorter_dists))\n",
    "        # Gives interpolated radial distances for RV with matching dimension to LV\n",
    "        shorter_dists_interped = np.interp(x=x_interp, xp=x_current, fp=shorter_dists)\n",
    "        # Iterate over LV dists in reverse since RV and LV should be *mirror* images\n",
    "        correlations[i] = scipy.stats.pearsonr(longer_dists[::-1], shorter_dists_interped).correlation\n",
    "\n",
    "    return correlations.mean(), correlations.std()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "echonet_video_fp = (Path\n",
    "(config[\"ECHONET_VIDEO_DIR\"]) / config[\"VIDEONAME\"]).with_suffix(\".avi\")\n",
    "echonet_video = echonet.utils.loadvideo(str(echonet_video_fp))\n",
    "echonet_video = echonet_video.transpose((1, 2, 3, 0)) # Put colour axis at end for easier colouring of pixels\n",
    "\n",
    "LV_masks = np.load(config[\"LV_MASKS\"])\n",
    "RV_masks = np.load(config[\"RV_MASKS\"])\n",
    "\n",
    "num_frames, frame_height, frame_width = LV_masks.shape\n",
    "out_height = (frame_height + frame_height // 8) * 4\n",
    "out_width = frame_width * 4\n",
    "out_size = (out_width, out_height)\n",
    "if WRITE:\n",
    "    print(f\"Size: ({frame_width}, {frame_height}) -> ({out_size})\")\n",
    "\n",
    "WINDOW = f\"Segmentation: {config['VIDEONAME']}.avi\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "\n",
    "i = 0\n",
    "is_playing = True\n",
    "\n",
    "if WRITE:\n",
    "    writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), 30, out_size)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if i >= num_frames:\n",
    "            i = 0\n",
    "            if WRITE:\n",
    "                break\n",
    "        elif i < 0:\n",
    "            i = num_frames - 1\n",
    "\n",
    "        # Copy data for this particular frame\n",
    "        frame = echonet_video[i].copy()\n",
    "        LV_mask = LV_masks[i].copy()\n",
    "        RV_mask = RV_masks[i].copy()\n",
    "\n",
    "        ######## SEGMENTATIONS\n",
    "        frame[LV_mask] = RED\n",
    "        frame[RV_mask] = BLUE\n",
    "\n",
    "\n",
    "        RV_image = mask_to_image(RV_mask)\n",
    "        \n",
    "        RV_contours, _ = cv2.findContours(RV_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        RV_contour = RV_contours[0]\n",
    "        RV_contour = np.squeeze(RV_contour)\n",
    "        RV_apex = RV_contour[np.argmin(RV_contour[:, 1])]\n",
    "        RV_centre = np.array(get_centroid(RV_mask))\n",
    "        RV_radial_dists = np.linalg.norm(RV_contour - RV_centre, axis=1)\n",
    "        LV_radial_dists = get_radial_distances(LV_mask)\n",
    "        cv2.circle(frame, (int(RV_apex[0]), int(RV_apex[1])), 2, GREEN.tolist(), -1)\n",
    "        cv2.circle(frame, (int(RV_centre[0]), int(RV_centre[1])), 2, MAGENTA.tolist(), -1)\n",
    "\n",
    "        # LV_box = get_min_area_box(mask_to_image(LV_mask))\n",
    "        # RV_box = get_min_area_box(mask_to_image(RV_mask))\n",
    "        # cv2.drawContours(frame, [LV_box], 0, YELLOW.tolist())\n",
    "        # cv2.drawContours(frame, [RV_box], 0, ORANGE.tolist())\n",
    "\n",
    "        ####### ADD FRAME COUNTER AT TOP\n",
    "        top_border = np.zeros((frame_height // 8, frame_width, 3), dtype=frame.dtype)\n",
    "        top_border[:, :] = np.expand_dims(LIGHT_GREY, (0, 1))\n",
    "        cv2.putText(top_border, f\"Frame {i+1}/{num_frames}\", org=(5,10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.25, color=RED.tolist())\n",
    "        frame = np.concatenate([top_border, frame], axis=0)\n",
    "\n",
    "        ######## SHOW SEGMENTATION AND HANDLE KEYPRESS\n",
    "        cv2.imshow(WINDOW, frame)\n",
    "\n",
    "        if WRITE:\n",
    "            frame = cv2.resize(frame, out_size)\n",
    "            writer.write(frame)\n",
    "\n",
    "        keypress = cv2.waitKey(25) & 0xFF\n",
    "        if keypress == ord('q'):\n",
    "            break\n",
    "        elif keypress == ord(' '):\n",
    "            is_playing = not is_playing\n",
    "        elif keypress == ord('a'):\n",
    "            i -= 1\n",
    "        elif keypress == ord('d'):\n",
    "            i += 1\n",
    "        else:\n",
    "            if is_playing:\n",
    "                i += 1\n",
    "finally:\n",
    "    cv2.destroyAllWindows() \n",
    "    if WRITE:\n",
    "        writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15706245592314547, 0.20091007186503368)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_radial_distance_correlation(LV_masks, RV_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
