{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining original and flipped segmentations to get purely right-ventricle segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import echonet\n",
    "\n",
    "# print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_SEGMENT_DIR = Path(\"output/segmentation/all-patients\")\n",
    "RIGHT_SEGMENT_DIR = Path(\"output/segmentation/flipped\")\n",
    "ECHONET_VIDEO_DIR = Path(\"/home/lex/data/echonet-data/Videos\")\n",
    "OUTPUT_DIR = Path(\"output/right-only-segmentation\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RED = np.array([255, 0, 0])\n",
    "GREEN = np.array([0, 255, 0])\n",
    "BLUE = np.array([0, 0, 255])\n",
    "ORANGE = np.array([255, 165, 0])\n",
    "LIGHT_GREY = np.array([211, 211, 211])\n",
    "MAGENTA = np.array([255, 0, 255])\n",
    "YELLOW = np.array([255, 255, 0])\n",
    "\n",
    "DO_SAVE_RIGHT_ONLY_SEGMENTATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heights(mask: np.ndarray):\n",
    "    \"\"\"Returns array of heights of mask for each frame!\"\"\"\n",
    "    frame_indices, row_indices = np.where(mask.any(axis=1)==True)\n",
    "\n",
    "    heights = []\n",
    "    for frame_index in range(mask.shape[0]):\n",
    "        this_frame = frame_indices == frame_index\n",
    "\n",
    "        if len(row_indices[this_frame]) == 0:\n",
    "            # print(f\"Frame #{frame_index} appears to have no segmentations? Treating this as zero height...\")\n",
    "            heights.append(0)\n",
    "            continue\n",
    "\n",
    "        min_row, max_row = (min(row_indices[this_frame]), max(row_indices[this_frame]))\n",
    "        height = max_row - min_row\n",
    "        heights.append(height)\n",
    "\n",
    "    heights = np.array(heights)\n",
    "    return heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_SAVE_RIGHT_ONLY_SEGMENTATIONS:\n",
    "    left_segment_mask_fps = [p for p in (LEFT_SEGMENT_DIR / \"segmentation_masks\").iterdir()]\n",
    "    for left_segment_mask_fp in tqdm(left_segment_mask_fps):\n",
    "        # Get associated segment masks for this particular video\n",
    "        # video_mask_name = video_fp.with_suffix(\".npy\").name # Turns \"path/to/video.avi\" into \"video.npy\"\n",
    "        video_stem = Path(left_segment_mask_fp.stem) # turns \"path/to/0x12345.npy\" into just \"0x12345\"\n",
    "        right_segment_mask_fp = RIGHT_SEGMENT_DIR / \"segmentation_masks\" / video_stem.with_suffix(\".npy\")\n",
    "        echonet_video_fp = ECHONET_VIDEO_DIR / video_stem.with_suffix(\".avi\")\n",
    "        # print(f\"Processing {echonet_video_fp}...\")\n",
    "\n",
    "        left_segment_mask = np.load(left_segment_mask_fp)\n",
    "        right_segment_mask = np.load(right_segment_mask_fp)\n",
    "        echonet_video = echonet.utils.loadvideo(str(echonet_video_fp)) # (colours, frames, height, width)\n",
    "\n",
    "        # Since right mask comes from flipped version of video, we need to flip it back to normal (i.e. left-to-right)\n",
    "        right_segment_mask = np.flip(right_segment_mask, axis=-1)\n",
    "\n",
    "        # Keep track of the mistaken left ventricle segmentation by the \"right\" segmentation mask\n",
    "        mistaken_left_mask = left_segment_mask & right_segment_mask\n",
    "        # Subtract those mistaken left ventricle parts from the right segmentation\n",
    "        right_only_mask = right_segment_mask ^ (mistaken_left_mask)\n",
    "\n",
    "        # Get heights of left and right ventricles, check if right ventricle appears unreasonably large (i.e. probably including atrium accidentally!)\n",
    "        left_heights = get_heights(left_segment_mask)\n",
    "        right_heights = get_heights(right_only_mask)\n",
    "        frames_with_too_large_RV_mask = right_heights > 0.8 * left_heights\n",
    "\n",
    "        # Put colour channels at end to make it easier to assign pixel colours\n",
    "        echonet_video = echonet_video.transpose((1, 2, 3, 0)) # I.e. now (frames, height, width, colours)\n",
    "        echonet_video[left_segment_mask] = RED\n",
    "        echonet_video[right_only_mask] = BLUE\n",
    "        echonet_video[mistaken_left_mask] = GREEN\n",
    "            \n",
    "        border_thickness = 2\n",
    "        echonet_video[frames_with_too_large_RV_mask, 0:border_thickness, :] = ORANGE\n",
    "        echonet_video[frames_with_too_large_RV_mask, -border_thickness:, :] = ORANGE\n",
    "        echonet_video[frames_with_too_large_RV_mask, :, 0:border_thickness] = ORANGE\n",
    "        echonet_video[frames_with_too_large_RV_mask, :, -border_thickness:] = ORANGE\n",
    "\n",
    "        # Transpose video back to original shape now and save\n",
    "        echonet_video = echonet_video.transpose((3, 0, 1, 2)) # now (colours, frames, height, width) as before\n",
    "        output_fp = OUTPUT_DIR / video_stem.with_suffix(\".avi\")\n",
    "\n",
    "        echonet.utils.savevideo(str(output_fp), echonet_video, 30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering out garbage data\n",
    "Here, we'll be trying to discard any videos that are not A4C views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(p1, p2, xs):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    \n",
    "    gradient = (y2 - y1) / (x2 - x1)\n",
    "    ys = gradient * (xs - x1) + y1\n",
    "    ys = np.intp(ys)\n",
    "    \n",
    "    coords_list = list(zip(xs, ys))\n",
    "    return coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_area_box(image):\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume we're only interested in max area contour\n",
    "    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    biggest_contour = contours[max_index]\n",
    "\n",
    "    min_area_rect = cv2.minAreaRect(biggest_contour)\n",
    "    box = np.intp(cv2.boxPoints(min_area_rect))\n",
    "    \n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_two_parallel_lines(points1, points2):\n",
    "    (x1, y1), (x2, y2) = points1\n",
    "    (x3, y3), (x4, y4) = points2\n",
    "\n",
    "    # Double check that gradients of these two lines are the same\n",
    "    m = (y2 - y1)/(x2 - x1)\n",
    "    # assert m == (y4 - y3)/(x4 - x3)\n",
    "\n",
    "    # y - y1 = m(x - x1)\n",
    "    # y = mx - m x1 + y1\n",
    "    # y = mx + (y1 - m x1) == mx + c1\n",
    "    # d = |c2 - c1| / sqrt(m^2 + 1)\n",
    "    c1 = y1 - m * x1\n",
    "    c2 = y3 - m * x3\n",
    "    d = abs(c2 - c1) / math.sqrt(m**2 + 1)\n",
    "    return d\n",
    "\n",
    "    # # Starting with y - y1= m(x - x1), we end up with\n",
    "    # # -x + (1/m) y + (x1 - y1/m) = 0, which we identify as\n",
    "    # # ax + by + c = 0\n",
    "    # c1 = x1 - y1 / m # c for first line\n",
    "    # c2 = x3 - y3 / m # c fo second line\n",
    "    # a = -1\n",
    "    # b = 1 / m\n",
    "\n",
    "    # # Distance between two parallel lines then given by the following\n",
    "    # d = abs(c1 - c2) / math.sqrt(a**2 + b**2)\n",
    "    # # d = abs(x1 - x2 + y2/m - y1/m) / math.sqrt(1/m**2 + 1)\n",
    "    # return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEONAME = \"0X1A58C9DFE12C7953\"\n",
    "\n",
    "LEFT_SEGMENTATION_MASK_FP = Path(f\"/home/lex/Development/ultrasound/output/segmentation/all-patients/segmentation_masks/{VIDEONAME}.npy\")\n",
    "FLIPPED_SEGMENTATION_MASK_FP = Path(f\"/home/lex/Development/ultrasound/output/segmentation/flipped/segmentation_masks/{VIDEONAME}.npy\")\n",
    "ECHONET_VIDEO_FP = Path(f\"/home/lex/data/echonet-data/Videos/{VIDEONAME}.avi\")\n",
    "\n",
    "left_segmentation_mask = np.load(LEFT_SEGMENTATION_MASK_FP)\n",
    "flipped_segmentation_mask = np.load(FLIPPED_SEGMENTATION_MASK_FP)\n",
    "flipped_segmentation_mask = np.flip(flipped_segmentation_mask, -1)\n",
    "intersection_mask = left_segmentation_mask & flipped_segmentation_mask\n",
    "# Subtract those mistaken left ventricle parts from the right segmentation\n",
    "right_segmentation_mask = flipped_segmentation_mask ^ intersection_mask\n",
    "# right_segmentation_mask = right_segmentation_mask.astype(np.uint8) * 255\n",
    "\n",
    "echonet_video = echonet.utils.loadvideo(str(ECHONET_VIDEO_FP))\n",
    "echonet_video = echonet_video.transpose((1, 2, 3, 0))\n",
    "\n",
    "num_frames, height, width, num_channels = echonet_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RV areas\n",
    "right_segmentation_mask_image = right_segmentation_mask.astype(np.uint8) * 255\n",
    "right_contours_list = [cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) for frame in right_segmentation_mask_image]\n",
    "right_contours_list = [x[0] for x in right_contours_list]\n",
    "\n",
    "right_max_areas = []\n",
    "for i, right_contours in enumerate(right_contours_list):\n",
    "    # print(f\"i = {i}\")\n",
    "    right_areas = [cv2.contourArea(contour) for contour in right_contours]\n",
    "    max_area = max(right_areas)\n",
    "    right_max_areas.append(max_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean septum width: 5.811004901334838 +/- 2.477535625421556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_865457/4048570368.py:6: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m = (y2 - y1)/(x2 - x1)\n",
      "/tmp/ipykernel_865457/4048570368.py:15: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  d = abs(c2 - c1) / math.sqrt(m**2 + 1)\n"
     ]
    }
   ],
   "source": [
    "# Calculate estimated septum widths using distance between left and right segmentations' tightest boxes\n",
    "septum_widths = np.zeros(num_frames)\n",
    "for i, (left_mask, right_mask) in enumerate(zip(left_segmentation_mask, right_segmentation_mask)):\n",
    "    left_segmentation = left_mask.astype(np.uint8) * 255\n",
    "    right_segmentation = right_mask.astype(np.uint8) * 255\n",
    "\n",
    "    LV_box = get_min_area_box(left_segmentation)\n",
    "    RV_box = get_min_area_box(right_segmentation)\n",
    "    top_left_LV, top_right_LV, bottom_right_LV, bottom_left_LV = LV_box\n",
    "    top_left_RV, top_right_RV, bottom_right_RV, bottom_left_RV = RV_box\n",
    "\n",
    "    dist = distance_between_two_parallel_lines([top_right_RV, bottom_right_RV], [top_left_LV, bottom_left_LV])\n",
    "    septum_widths[i] = dist\n",
    "\n",
    "# Will get NAN distances when the two bounding boxes touch each other (leads to divide by zero), so set those to distance zero\n",
    "septum_widths[np.isnan(septum_widths)] = 0\n",
    "\n",
    "print(f\"Mean septum width: {np.mean(septum_widths)} +/- {np.std(septum_widths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Septum width: 6.50\n",
      "Septum width: 8.49\n",
      "RV Area growth: 0.93\n",
      "Septum width: 9.51\n",
      "RV Area growth: 1.01\n",
      "Septum width: 10.04\n",
      "RV Area growth: 1.01\n",
      "Septum width: 10.42\n",
      "RV Area growth: 0.98\n",
      "Septum width: 9.00\n",
      "RV Area growth: 0.99\n",
      "Septum width: 7.87\n",
      "RV Area growth: 0.97\n",
      "Septum width: 5.16\n",
      "RV Area growth: 1.07\n",
      "Septum width: 0.00\n",
      "RV Area growth: 1.04\n",
      "Septum width: 0.00\n",
      "RV Area growth: 0.92\n",
      "Septum width: 0.00\n",
      "RV Area growth: 0.98\n",
      "Septum width: 3.61\n",
      "RV Area growth: 0.95\n",
      "Septum width: 3.75\n",
      "RV Area growth: 0.95\n",
      "Septum width: 2.30\n",
      "RV Area growth: 0.98\n",
      "Septum width: 2.31\n",
      "RV Area growth: 0.90\n",
      "Septum width: 1.00\n",
      "RV Area growth: 0.94\n",
      "Septum width: 4.03\n",
      "RV Area growth: 0.98\n",
      "Septum width: 0.00\n",
      "RV Area growth: 1.07\n",
      "Septum width: 0.00\n",
      "RV Area growth: 0.95\n",
      "Septum width: 2.06\n",
      "RV Area growth: 0.99\n",
      "Septum width: 3.12\n",
      "RV Area growth: 1.06\n"
     ]
    }
   ],
   "source": [
    "WINDOW = \"Mask\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"Erosion\", cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"Dilation\", cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"Denoised\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "i = 0\n",
    "is_playing = True\n",
    "\n",
    "while True:\n",
    "    if i >= num_frames:\n",
    "        i = 0\n",
    "        print(\"Video looped!\")\n",
    "    elif i < 0:\n",
    "        i = num_frames - 1\n",
    "\n",
    "    frame = echonet_video[i].copy()\n",
    "    ret, denoised = cv2.threshold(frame,20,255,cv2.THRESH_TOZERO)\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(denoised,None,10,10,7,21)\n",
    "    # denoised = cv2.threshold(denoised,40,255,cv2.THRESH_TOZERO)\n",
    "    cv2.imshow(\"Denoised\", denoised)\n",
    "\n",
    "    frame_left_segmentation_mask = left_segmentation_mask[i]\n",
    "    frame_right_segmentation_mask = right_segmentation_mask[i].copy()\n",
    "    frame_intersection_segmentation_mask = intersection_mask[i]\n",
    "\n",
    "    # frame[frame_left_segmentation_mask] = RED\n",
    "    # frame[frame_intersection_segmentation_mask] = GREEN\n",
    "\n",
    "    # Find tightest box around LV segmentation\n",
    "    frame_left_segmentation = frame_left_segmentation_mask.astype(np.uint8) * 255\n",
    "    LV_box = get_min_area_box(frame_left_segmentation)\n",
    "    cv2.drawContours(frame,[LV_box],0, MAGENTA.tolist())\n",
    "    top_left_LV, top_right_LV, bottom_right_LV, bottom_left_LV = LV_box\n",
    "\n",
    "    cutoff_x = np.intp(np.arange(0, frame.shape[1]))\n",
    "    bottom_cutoff_points = make_line(bottom_left_LV, bottom_right_LV, cutoff_x)\n",
    "    cv2.line(frame, bottom_cutoff_points[0], bottom_cutoff_points[-1], MAGENTA.tolist())\n",
    "    \n",
    "    top_cutoff_points = make_line(top_left_LV, top_right_LV, cutoff_x)\n",
    "    cv2.line(frame, top_cutoff_points[0], top_cutoff_points[-1], MAGENTA.tolist())\n",
    "    \n",
    "    right_cutoff_points_untrimmed = make_line(bottom_left_LV, top_left_LV, cutoff_x)\n",
    "    right_cutoff_points = []\n",
    "    for x, y in right_cutoff_points_untrimmed:\n",
    "        if y >=0 and y < frame.shape[1]:\n",
    "            right_cutoff_points.append((x, y))\n",
    "\n",
    "    cv2.line(frame, right_cutoff_points[0], right_cutoff_points[-1], MAGENTA.tolist())\n",
    "\n",
    "    for x, y in bottom_cutoff_points:\n",
    "        frame_right_segmentation_mask[y:, x] = False\n",
    "    for x, y in right_cutoff_points:\n",
    "        frame_right_segmentation_mask[:y, x] = False\n",
    "\n",
    "    frame[frame_right_segmentation_mask] = BLUE\n",
    "\n",
    "    # Draw box around RV segmentation, and determine shortest distance to LV box\n",
    "    frame_right_segmentation = frame_right_segmentation_mask.astype(np.uint8) * 255\n",
    "    RV_box = get_min_area_box(frame_right_segmentation)\n",
    "    cv2.drawContours(frame,[RV_box],0, YELLOW.tolist())\n",
    "    septum_width = septum_widths[i]\n",
    "    print(f\"Septum width: {septum_width:.2f}\")\n",
    "    \n",
    "    # kernel = np.ones((3, 3))\n",
    "    # kernel = np.array([\n",
    "    #     [1, 0, 0],\n",
    "    #     [0, 1, 0],\n",
    "    #     [0, 0, 1]\n",
    "    # ], dtype=np.uint8)\n",
    "    kernel = np.array([\n",
    "        [1, 1],\n",
    "        [1, 1]\n",
    "    ], dtype=np.uint8)\n",
    "    # kernel = np.array([\n",
    "    #     [0, 0, 0, 0, 1, 1],\n",
    "    #     [0, 0, 0, 1, 1, 1],\n",
    "    #     [0, 0, 1, 1, 1, 1],\n",
    "    #     [0, 1, 1, 1, 1, 1],\n",
    "    #     [1, 1, 1, 1, 1, 1],\n",
    "    #     [1, 1, 1, 1, 1, 1],\n",
    "    # ], dtype=np.uint8)\n",
    "    kernel = np.array([\n",
    "        [0, 0, 0, 1],\n",
    "        [0, 0, 1, 1],\n",
    "        [0, 1, 1, 1],\n",
    "        [1, 1, 1, 1],\n",
    "    ], dtype=np.uint8)\n",
    "    frame_right_segmentation = cv2.erode(frame_right_segmentation, kernel, cv2.BORDER_REFLECT, iterations=3)\n",
    "    cv2.imshow(\"Erosion\", frame_right_segmentation)\n",
    "\n",
    "    # frame[frame_right_segmentation > 0] = ORANGE\n",
    "\n",
    "    # Find contour with max area|\n",
    "    contours, hierarchy = cv2.findContours(frame_right_segmentation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    biggest_contour = contours[max_index]\n",
    "\n",
    "    biggest_right_segmentation = np.zeros(frame_right_segmentation.shape)\n",
    "    biggest_right_segmentation = cv2.drawContours(biggest_right_segmentation, [biggest_contour], -1, 255, -1)\n",
    "\n",
    "    dilation_kernel = np.ones((8, 8))\n",
    "    # dilation_kernel = np.array([\n",
    "    #     [0, 0, 0, 0, 1, 1],\n",
    "    #     [0, 0, 0, 1, 1, 1],\n",
    "    #     [0, 0, 1, 1, 1, 0],\n",
    "    #     [0, 1, 1, 1, 0, 0],\n",
    "    #     [1, 1, 1, 0, 0, 0],\n",
    "    #     [1, 1, 0, 0, 0, 0],\n",
    "    # ], dtype=np.uint8)\n",
    "    # dilation_kernel = np.array([\n",
    "    #     [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    #     [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    #     [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    #     [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    #     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    #     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    #     [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    #     [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "    #     [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "    #     [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    # ], dtype=np.uint8)\n",
    "    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9))\n",
    "    dilation_kernel += dilation_kernel.transpose()\n",
    "    frame_right_segmentation_dilated = cv2.dilate(biggest_right_segmentation, dilation_kernel, iterations=1, borderType=cv2.BORDER_REFLECT)\n",
    "    cv2.imshow(\"Dilation\", frame_right_segmentation_dilated)\n",
    "\n",
    "    frame_right_segmentation_dilated_mask = frame_right_segmentation_dilated > 0\n",
    "    overlap_mask = frame_right_segmentation_mask & frame_right_segmentation_dilated_mask\n",
    "    # frame[overlap_mask] = ORANGE\n",
    "    # difference_mask = frame_right_segmentation_dilated_mask & (~frame_right_segmentation_mask)\n",
    "    # frame[difference_mask] = MAGENTA\n",
    "\n",
    "    this_area = right_max_areas[i]\n",
    "    if i > 0: \n",
    "        prev_area = right_max_areas[i - 1]\n",
    "        growth = this_area/ prev_area\n",
    "        print(f\"RV Area growth: {growth:.2f}\")\n",
    "        if growth > 1.2:\n",
    "            frame[:10, :] = ORANGE\n",
    "\n",
    "    top_border = np.zeros((height // 8, width, 3), dtype=frame.dtype)\n",
    "    top_border[:, :] = np.expand_dims(LIGHT_GREY, (0, 1))\n",
    "    cv2.putText(top_border, f\"Frame {i+1}/{num_frames}\", org=(5,10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.25, color=(255, 0, 0))\n",
    "    frame = np.concatenate([top_border, frame], axis=0)\n",
    "    frame = np.flip(frame, -1)\n",
    "    cv2.imshow(WINDOW, frame)\n",
    "\n",
    "    keypress = cv2.waitKey(50) & 0xFF\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "    elif keypress == ord(' '):\n",
    "        is_playing = not is_playing\n",
    "    elif keypress == ord('a'):\n",
    "        i -= 1\n",
    "    elif keypress == ord('d'):\n",
    "        i += 1\n",
    "    else:\n",
    "        if is_playing:\n",
    "            i += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f172eeab591fffc7206196735bfc2e29f166a162a3789422c4782f1097623d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
