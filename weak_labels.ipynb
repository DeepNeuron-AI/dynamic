{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining original and flipped segmentations to get purely right-ventricle segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import echonet\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Just some types for us to use in type hints to make dev easier\n",
    "Point = List[np.intp]\n",
    "Box = Tuple[Point, Point, Point, Point]\n",
    "Rectangle = Tuple[Point, Tuple[float, float], float] # [centre, (width, height), angle]\n",
    "\n",
    "# Directories containing both original and flipped segmentation masks\n",
    "LEFT_SEGMENTATION_DIR = Path(config[\"LEFT_SEGMENT_DIR\"]) # e.g. LEFT_SEGMENT_DIR=\"output/segmentation/all-patients\"\n",
    "LEFT_SEGMENTATION_MASK_DIR = LEFT_SEGMENTATION_DIR / \"segmentation_masks\" # remember that you have to have run the modified segmentation.py to get this segmentations sub-directory!\n",
    "FLIPPED_SEGMENTATION_DIR = Path(config[\"FLIPPED_SEGMENT_DIR\"]) # e.g. FLIPPED_SEGMENT_DIR=\"output/segmentation/flipped\"\n",
    "FLIPPED_SEGMENTATION_MASK_DIR = FLIPPED_SEGMENTATION_DIR / \"segmentation_masks\"\n",
    "\n",
    "ECHONET_VIDEO_DIR = Path(config[\"ECHONET_VIDEO_DIR\"]) # e.g. ECHONET_VIDEO_DIR=\"/home/lex/data/echonet-data/Videos\"\n",
    "\n",
    "# Can assign these colours to numpy arrays so long as the colours are stored in\n",
    "# the last axis of the target array (e.g. image.shape =(112, 112, 3), but not\n",
    "# image.shape = (3, 112, 112)). \n",
    "# Just do image[y_vals, x_vals] = MAGENTA\n",
    "# IMPORTANT: if using within an *opencv* function, you'll want to do \n",
    "# COLOUR.tolist() to convert these to python primitives, else opencv complains about\n",
    "# datatypes\n",
    "RED = np.array([255, 0, 0])\n",
    "GREEN = np.array([0, 255, 0])\n",
    "BLUE = np.array([0, 0, 255])\n",
    "ORANGE = np.array([255, 165, 0])\n",
    "LIGHT_GREY = np.array([211, 211, 211])\n",
    "MAGENTA = np.array([255, 0, 255])\n",
    "YELLOW = np.array([255, 255, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heights(mask: np.ndarray) -> List[int]:\n",
    "    \"\"\"Returns array of heights of mask for each frame!\"\"\"\n",
    "    frame_indices, row_indices = np.where(mask.any(axis=1)==True)\n",
    "\n",
    "    heights = []\n",
    "    for frame_index in range(mask.shape[0]):\n",
    "        this_frame = frame_indices == frame_index\n",
    "\n",
    "        if len(row_indices[this_frame]) == 0:\n",
    "            # print(f\"Frame #{frame_index} appears to have no segmentations? Treating this as zero height...\")\n",
    "            heights.append(0)\n",
    "            continue\n",
    "\n",
    "        min_row, max_row = (min(row_indices[this_frame]), max(row_indices[this_frame]))\n",
    "        height = max_row - min_row\n",
    "        heights.append(height)\n",
    "\n",
    "    heights = np.array(heights)\n",
    "    return heights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering out garbage data\n",
    "Here, we'll be trying to discard any videos that are not A4C views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(rect: Rectangle) -> float:\n",
    "    _, (width, height), angle = rect\n",
    "    if width < height:\n",
    "        return 0 - angle\n",
    "    elif height <= width:\n",
    "        return 90 - angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOTTOM_RIGHT = 0\n",
    "BOTTOM_LEFT = 1\n",
    "TOP_RIGHT = 2\n",
    "TOP_LEFT = 3\n",
    "\n",
    "def find_corner(rect: Rectangle, which: int) -> Point:\n",
    "    \"\"\"\n",
    "    (Attempts to) find the \"bottom-right\" corner of the given rectangle. This \n",
    "    can at least handle rectangles rotated by an angle in the range [0, 90).\n",
    "    \"\"\"\n",
    "    # angle = rect[-1]\n",
    "    angle = get_angle(rect)\n",
    "    box = np.intp(cv2.boxPoints(rect))\n",
    "\n",
    "    # Critical angle regions are: [-90, -45), [-45, 0), [0, 45), [45, 90] ?\n",
    "    if (-90 <= angle < -45) or (0 <= angle < 45):\n",
    "        if which == BOTTOM_LEFT:\n",
    "            return box[3]\n",
    "        elif which == TOP_LEFT:\n",
    "            return box[0]\n",
    "        elif which == TOP_RIGHT:\n",
    "            return box[1]\n",
    "        elif which == BOTTOM_RIGHT:\n",
    "            return box[2]\n",
    "    elif (-45 <= angle < 0) or (45 <= angle <= 90):\n",
    "        if which == BOTTOM_LEFT:\n",
    "            return box[0]\n",
    "        elif which == TOP_LEFT:\n",
    "            return box[1]\n",
    "        elif which == TOP_RIGHT:\n",
    "            return box[2]\n",
    "        elif which == BOTTOM_RIGHT:\n",
    "            return box[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_image(mask: np.ndarray, max_val: int = 255) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a boolean mask array to a pure black and white image. Useful if\n",
    "    you start with a mask but then want to find contours and perform other image\n",
    "    analysis on that mask    \n",
    "    \"\"\"\n",
    "    return mask.astype(np.uint8) * max_val\n",
    "\n",
    "def image_to_mask(image: np.ndarray, threshold: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a black and white image to a boolean mask, selecting every pixel \n",
    "    whose intensity is **greater than or equal to the threshold**\n",
    "    \"\"\"\n",
    "    return image >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload here so we can just change the VIDEONAME in .env without having to \n",
    "# go back and rerun top cell\n",
    "config = dotenv_values(\".env\")\n",
    "VIDEONAME = config[\"VIDEONAME\"] # e.g. VIDEONAME=\"0X1DB488AC3583E3D6\"\n",
    "\n",
    "LEFT_SEGMENTATION_MASK_FP = LEFT_SEGMENTATION_MASK_DIR / f\"{VIDEONAME}.npy\"\n",
    "FLIPPED_SEGMENTATION_MASK_FP = FLIPPED_SEGMENTATION_MASK_DIR / f\"{VIDEONAME}.npy\"\n",
    "ECHONET_VIDEO_FP = ECHONET_VIDEO_DIR / f\"{VIDEONAME}.avi\"\n",
    "\n",
    "left_segmentation_masks = np.load(LEFT_SEGMENTATION_MASK_FP)\n",
    "flipped_segmentation_masks = np.load(FLIPPED_SEGMENTATION_MASK_FP)\n",
    "flipped_segmentation_masks = np.flip(flipped_segmentation_masks, -1) # Flip back to original orientation\n",
    "\n",
    "# Subtract those mistaken left ventricle parts from the right segmentation\n",
    "right_segmentation_masks = flipped_segmentation_masks & ~left_segmentation_masks\n",
    "\n",
    "left_segmentations = mask_to_image(left_segmentation_masks)\n",
    "right_segmentations = mask_to_image(right_segmentation_masks)\n",
    "\n",
    "echonet_video = echonet.utils.loadvideo(str(ECHONET_VIDEO_FP))\n",
    "echonet_video = echonet_video.transpose((1, 2, 3, 0))\n",
    "\n",
    "num_frames, height, width, num_channels = echonet_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(p1: Point, p2: Point, xs: List[int]) -> List[Point]:\n",
    "    \"\"\"\n",
    "    Extends a line between the given pair of points for all given x values and\n",
    "    returns the list of points on this line.\n",
    "    \n",
    "    This clips the points for you in case any of the given x values correspond to\n",
    "    y values outside of the image's borders.\n",
    "    \"\"\"\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    \n",
    "    gradient = (y2 - y1) / (x2 - x1)\n",
    "    ys = gradient * (xs - x1) + y1\n",
    "    ys = np.intp(ys)\n",
    "    \n",
    "    all_points = list(zip(xs, ys))\n",
    "    points_within_frame = []\n",
    "    # Only include points that would be within the image's borders\n",
    "    for point in all_points:\n",
    "        x, y = point\n",
    "        if (0 <= x < width) and (0 <= y < height):\n",
    "            points_within_frame.append(point)\n",
    "\n",
    "    return points_within_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_area_rect(image: np.ndarray) -> Rectangle:\n",
    "    \"\"\"\n",
    "    Finds the largest contour in the given image, and returns the minimum area\n",
    "    rectangle that bounds it.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ((centre_x, centre_y), (width, height), angle)\n",
    "    \"\"\"\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume we're only interested in max area contour\n",
    "    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    biggest_contour = contours[max_index]\n",
    "\n",
    "    min_area_rect = cv2.minAreaRect(biggest_contour)\n",
    "    return min_area_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_area_box(image: np.ndarray) -> Box:\n",
    "    \"\"\"\n",
    "    Similar to get_min_area_rect(), but instead returns the coordinates of the\n",
    "    box's four corners.\n",
    "    \"\"\"\n",
    "    min_area_rect = get_min_area_rect(image)\n",
    "    box = np.intp(cv2.boxPoints(min_area_rect))\n",
    "    \n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpendicular_distance_to_line(line: List[List[int]], point: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the perpendicular distance from a straight line to a given point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line: List[List[int]]\n",
    "        `line` is a *p0 - angleair* of points, where each point contains a single x and y\n",
    "        value.\n",
    "    point: List[int]\n",
    "        A pair of x and y values.\n",
    "    \"\"\"\n",
    "    (x1, y1), (x2, y2) = line\n",
    "    x3, y3 = point\n",
    "\n",
    "    m = (y2 -y1) / (x2 - x1)\n",
    "    a = -1\n",
    "    b = 1 / m\n",
    "    c = x1 - y1 / m\n",
    "\n",
    "    d = abs(a * x3 + b * y3 + c) / math.sqrt(a**2 + b**2)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LV boxes and rectangles\n",
    "LV_boxes = [get_min_area_box(left_segmentation) for left_segmentation in left_segmentations]\n",
    "LV_rects = [get_min_area_rect(left_segmentation) for left_segmentation in left_segmentations]\n",
    "LV_lines = [[find_corner(rect, BOTTOM_LEFT), find_corner(rect, TOP_LEFT)] for rect in LV_rects]\n",
    "LV_angles = [get_angle(rect) for rect in LV_rects]\n",
    "\n",
    "plt.hist(LV_angles, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include largest contour of right segmentation for each frame. This removes\n",
    "# any smaller, disconnected blobs\n",
    "right_segmentations_copy = right_segmentations.copy()\n",
    "right_segmentations = np.zeros(right_segmentations.shape, dtype=right_segmentations.dtype)\n",
    "for i, right_segmentation in enumerate(right_segmentations_copy):\n",
    "    right_contours, hierarchy = cv2.findContours(right_segmentation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(cnt) for cnt in right_contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    biggest_contour = right_contours[max_index]\n",
    "\n",
    "    biggest_right_segmentation = np.zeros(right_segmentation.shape)\n",
    "    biggest_right_segmentation = cv2.drawContours(biggest_right_segmentation, [biggest_contour], -1, 255, -1)\n",
    "    right_segmentations[i] = biggest_right_segmentation\n",
    "\n",
    "# Update masks too, would be nicer to have these masks and images automatically linked though!\n",
    "right_segmentation_masks = image_to_mask(right_segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim RV segmentations based on LV bounding box\n",
    "right_segmentations = np.zeros(shape=right_segmentations.shape, dtype=right_segmentations.dtype)\n",
    "\n",
    "bottom_cutoff_points_list = []\n",
    "top_cutoff_points_list = []\n",
    "right_cutoff_points_list = []\n",
    "\n",
    "cutoff_x = np.intp(np.arange(0, width))\n",
    "\n",
    "for i, (LV_box, LV_rect, right_segmentation_mask) in enumerate(zip(LV_boxes, LV_rects, right_segmentation_masks)):\n",
    "    if i == 10:\n",
    "        print(\"We're here\")\n",
    "\n",
    "    top_left_LV = find_corner(LV_rect, TOP_LEFT)\n",
    "    top_right_LV = find_corner(LV_rect, TOP_RIGHT)\n",
    "    bottom_left_LV = find_corner(LV_rect, BOTTOM_LEFT)\n",
    "    bottom_right_LV = find_corner(LV_rect, BOTTOM_RIGHT)\n",
    "\n",
    "    bottom_cutoff_points = make_line(bottom_left_LV, bottom_right_LV, cutoff_x)\n",
    "    bottom_cutoff_points_list.append(bottom_cutoff_points)\n",
    "\n",
    "    top_cutoff_points = make_line(top_left_LV, top_right_LV, cutoff_x)\n",
    "    top_cutoff_points_list.append(top_cutoff_points)\n",
    "\n",
    "    right_cutoff_points = make_line(bottom_left_LV, top_left_LV, cutoff_x)\n",
    "    right_cutoff_points_list.append(right_cutoff_points)\n",
    "\n",
    "    # Note we update the masks here, so we don't need to call image_to_mask()\n",
    "    # at end of this for loop!\n",
    "    for x, y in bottom_cutoff_points:\n",
    "        right_segmentation_mask[y:, x] = False\n",
    "    for x, y in right_cutoff_points:\n",
    "        right_segmentation_mask[:y, x] = False\n",
    "\n",
    "    right_segmentations[i] = mask_to_image(right_segmentation_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RV areas\n",
    "# Since we have already eliminated all but the largest contour, we simply always\n",
    "# use hardcoded index of 0 to access it!\n",
    "# Then extra index zero for contours because of opencv's return values\n",
    "RV_contours_list = [cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0][0] for frame in right_segmentations]\n",
    "RV_areas = [cv2.contourArea(contour) for contour in RV_contours_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RV_contours_list = [cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) for frame in right_segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_list = [contours[0] for contours in RV_contours_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contours = [len(cnt) for cnt in contours_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angle for bounding box of LV in each frame\n",
    "LV_box_angles = np.zeros(num_frames)\n",
    "for i, left_segmentation in enumerate(left_segmentations):\n",
    "    *_, angle = get_min_area_rect(left_segmentation)\n",
    "    LV_box_angles[i] = angle\n",
    "\n",
    "print(f\"Mean LV box angle: {np.mean(LV_box_angles)} +/- {np.std(LV_box_angles)}\")\n",
    "\n",
    "# Check how many times the box goes beyond three standard deviations\n",
    "mean, std = np.mean(LV_box_angles), np.std(LV_box_angles)\n",
    "bad_angle_mask = (LV_box_angles < mean - 1 * std) | ((LV_box_angles > mean + 1 * std))\n",
    "num_bad_angles = bad_angle_mask.sum()\n",
    "print(f\"Found {num_bad_angles} frames with suspicious LV bounding box angles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find septum widths\n",
    "septum_widths = []\n",
    "\n",
    "for right_segmentation, LV_line in zip(right_segmentations, LV_lines):\n",
    "    RV_rect = get_min_area_rect(right_segmentation)\n",
    "    RV_bottom_right = find_corner(RV_rect, BOTTOM_RIGHT)\n",
    "\n",
    "    x3, y3 = RV_bottom_right\n",
    "    # frame[y3:y3+2, x3:x3+2] = ORANGE\n",
    "    septum_width = perpendicular_distance_to_line(LV_line, RV_bottom_right)\n",
    "    septum_widths.append(septum_width)\n",
    "    # print(f\"Septum: {septum_width}\")\n",
    "\n",
    "print(f\"Mean septum width: {np.mean(septum_widths)} +/- {np.std(septum_widths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(septum_widths, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RV_boxes = [get_min_area_box(right_segmentation) for right_segmentation in right_segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use average estimated septum width and translate the LV segmentation's inner\n",
    "# edge by that amount to guess the right edge of the RV.\n",
    "mean_septum_width = np.mean(septum_widths)\n",
    "\n",
    "RV_boxes = []\n",
    "RV_lines = []\n",
    "for LV_box, LV_rect, LV_line, right_segmentation_mask, right_segmentation in zip(LV_boxes, LV_rects, LV_lines, right_segmentation_masks, right_segmentations):\n",
    "    LV_angle = LV_rect[-1]\n",
    "    \n",
    "    # Since we translate points *left*, and not necessarily perpendicular to LV\n",
    "    # line, we include factor of sin(angle)\n",
    "    translate_x = mean_septum_width / math.sin(math.radians(LV_angle))\n",
    "    RV_line = [point.copy() for point in LV_line]\n",
    "    for point in RV_line:\n",
    "        point[0] -= translate_x\n",
    "\n",
    "    RV_lines.append(RV_line)\n",
    "\n",
    "    RV_box = get_min_area_box(right_segmentation)\n",
    "    # Just in case we need to access this later\n",
    "    RV_boxes.append(RV_box)\n",
    "\n",
    "    # Now remove any pixels in RV segmentation that go beyond its expected inner\n",
    "    # edge\n",
    "    # Note this is a greedier \"right cutoff\" than before, should probs just name this better!\n",
    "    right_cutoff_points = make_line(RV_line[0], RV_line[1], cutoff_x)\n",
    "    for x, y in right_cutoff_points:\n",
    "        right_segmentation_mask[:y, x] = False\n",
    "\n",
    "# Update RV segmentation *images* based on these new masks\n",
    "right_segmentations = mask_to_image(right_segmentation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = \"Mask\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "\n",
    "i = 0\n",
    "is_playing = True\n",
    "\n",
    "\n",
    "while True:\n",
    "    if i >= num_frames:\n",
    "        i = 0\n",
    "        print(\"Video looped!\")\n",
    "    elif i < 0:\n",
    "        i = num_frames - 1\n",
    "\n",
    "    # Copy data for this particular frame\n",
    "    frame = echonet_video[i].copy()\n",
    "    left_segmentation_mask = left_segmentation_masks[i].copy()\n",
    "    left_segmentation = left_segmentations[i].copy()\n",
    "    right_segmentation_mask = right_segmentation_masks[i].copy()\n",
    "    right_segmentation = right_segmentations[i].copy()\n",
    "\n",
    "    # this_area = RV_areas[i]\n",
    "    # LV_line = LV_lines[i]\n",
    "    # RV_line = RV_lines[i]\n",
    "    LV_box = LV_boxes[i]\n",
    "    LV_rect = LV_rects[i]\n",
    "    LV_angle = get_angle(LV_rect)\n",
    "    # print(f\"{LV_angle:.2f}: {LV_box}\")\n",
    "    # RV_box = RV_boxes[i]\n",
    "    RV_box = get_min_area_box(right_segmentation)\n",
    "    RV_rect = get_min_area_rect(right_segmentation)\n",
    "    RV_angle = get_angle(RV_rect)\n",
    "    print(f\"{RV_angle:.2f}: {RV_box}: {RV_rect}\")\n",
    "\n",
    "    # \n",
    "    # if i > 0: \n",
    "    #     prev_area = RV_areas[i - 1]\n",
    "    #     growth = this_area / prev_area\n",
    "        # print(f\"RV Area growth: {growth:.2f}\")\n",
    "        # if growth > 1.2:\n",
    "        #     frame[:10, :] = ORANGE\n",
    "\n",
    "    # Add any drawings to the ultrasound here\n",
    "    # frame[left_segmentation_mask] = RED\n",
    "    frame[right_segmentation_mask] = BLUE\n",
    "    # Note this draws the outdated RV_box, before we cut out the septum!\n",
    "    cv2.drawContours(frame,[RV_box],0, YELLOW.tolist())\n",
    "    # cv2.drawContours(frame,[LV_box],0, YELLOW.tolist())\n",
    "    # cv2.line(frame, np.intp(LV_line[0]), np.intp(LV_line[1]), ORANGE.tolist())\n",
    "    # cv2.line(frame, np.intp(RV_line[0]), np.intp(RV_line[1]), RED.tolist())\n",
    "\n",
    "    # RV_rect = RV_rects[i]\n",
    "    bl, tl, br, tr = find_corner(RV_rect, BOTTOM_LEFT), find_corner(RV_rect, TOP_LEFT), find_corner(RV_rect, BOTTOM_RIGHT), find_corner(RV_rect, TOP_RIGHT)\n",
    "    frame[br[1], br[0]] = RED\n",
    "\n",
    "    top_border = np.zeros((height // 8, width, 3), dtype=frame.dtype)\n",
    "    top_border[:, :] = np.expand_dims(LIGHT_GREY, (0, 1))\n",
    "    cv2.putText(top_border, f\"Frame {i+1}/{num_frames}\", org=(5,10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.25, color=(255, 0, 0))\n",
    "    frame = np.concatenate([top_border, frame], axis=0)\n",
    "    frame = np.flip(frame, -1)\n",
    "    cv2.imshow(WINDOW, frame)\n",
    "\n",
    "    keypress = cv2.waitKey(50) & 0xFF\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "    elif keypress == ord(' '):\n",
    "        is_playing = not is_playing\n",
    "    elif keypress == ord('a'):\n",
    "        i -= 1\n",
    "    elif keypress == ord('d'):\n",
    "        i += 1\n",
    "    else:\n",
    "        if is_playing:\n",
    "            i += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LV_rects[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LV_rects[20])\n",
    "print(LV_rects[21])\n",
    "print(LV_rects[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{LV_rects[2][-1]:.256f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is just for playing around with rotated rectangles and their corners,\n",
    "# while we figure out how on earth opencv determines the angle in its return value\n",
    "# for cv2.minAreaRect()!\n",
    "WINDOW = \"Mask\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "\n",
    "frame = np.zeros((112, 112), dtype=np.uint8)\n",
    "rows,cols = frame.shape\n",
    "width = 30\n",
    "height = 60\n",
    "angle = 135\n",
    "centre_x = cols // 2\n",
    "centre_y = rows // 2\n",
    "corner1 = (centre_x - width // 2, centre_y - height // 2)\n",
    "corner2 = (centre_x + width // 2, centre_y + height // 2)\n",
    "frame = cv2.rectangle(frame, corner1, corner2, 255, -1)\n",
    "\n",
    "matrix = cv2.getRotationMatrix2D((56, 56), angle, 1)\n",
    "frame = cv2.warpAffine(frame, matrix, (cols, rows))\n",
    "\n",
    "box = get_min_area_box(frame)\n",
    "rect = get_min_area_rect(frame)\n",
    "our_angle = get_angle(rect)\n",
    "print(our_angle)\n",
    "print(rect)\n",
    "print(box)\n",
    "print(\"HERE?\")\n",
    "frame = np.zeros((112, 112), dtype=np.uint8)\n",
    "cv2.drawContours(frame,[box],0, 255)\n",
    "\n",
    "# bottom_left = find_corner(rect, BOTTOM_LEFT)\n",
    "# frame[bottom_left[1], bottom_left[0]] = 255\n",
    "\n",
    "frame = np.flip(frame, axis=-1)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(WINDOW, frame)\n",
    "\n",
    "    keypress = cv2.waitKey(50) & 0xFF\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_area_box(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f172eeab591fffc7206196735bfc2e29f166a162a3789422c4782f1097623d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
